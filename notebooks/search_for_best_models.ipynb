{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b701f00f",
   "metadata": {},
   "source": [
    "# Exploration phase — initial testing\n",
    "Here we try out different models on our data. The comments below explain exactly what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a2d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/12/25 19:16:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Using                                                                  <a href=\"file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/framework/project/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/framework/project/__init__.py#270\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'/opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/pyt</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">hon3.11/site-packages/kedro/framework/project/rich_logging.yml'</span> as     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         logging configuration.                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/12/25 19:16:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using                                                                  \u001b]8;id=641944;file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/framework/project/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703885;file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/framework/project/__init__.py#270\u001b\\\u001b[2m270\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'/opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/pyt\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mhon3.11/site-packages/kedro/framework/project/rich_logging.yml'\u001b[0m as     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         logging configuration.                                                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kedro.framework.session import KedroSession\n",
    "from kedro.framework.startup import bootstrap_project\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457b3910581c944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ścieżka projektu: /Users/kacperziebacz/Desktop/f1-pitstop-advisor-v2\n"
     ]
    }
   ],
   "source": [
    "project_path = Path.cwd().parent\n",
    "bootstrap_project(project_path)\n",
    "print(f\"Ścieżka projektu: {project_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddcb550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/12/25 19:16:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro is sending anonymous usage data with the sole purpose of improving <a href=\"file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro_telemetry/plugin.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plugin.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro_telemetry/plugin.py#243\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         the product. No personal data or IP addresses are stored on our side. To <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         variables, or create a `.telemetry` file in the current working          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         directory with the contents `consent: false`. To hide this message,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         explicitly grant or deny consent. Read more at                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.kedro.org/en/stable/configuration/telemetry.html</span>            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/12/25 19:16:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro is sending anonymous usage data with the sole purpose of improving \u001b]8;id=426370;file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro_telemetry/plugin.py\u001b\\\u001b[2mplugin.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=874545;file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro_telemetry/plugin.py#243\u001b\\\u001b[2m243\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         the product. No personal data or IP addresses are stored on our side. To \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK` environment \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         variables, or create a `.telemetry` file in the current working          \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         directory with the contents `consent: false`. To hide this message,      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         explicitly grant or deny consent. Read more at                           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.kedro.org/en/stable/configuration/telemetry.html\u001b[0m            \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/12/25 19:16:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">circuit_lap_data</span> <span style=\"font-weight: bold\">(</span>PickleDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>             <a href=\"file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/io/data_catalog.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/12/25 19:16:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mcircuit_lap_data\u001b[0m \u001b[1m(\u001b[0mPickleDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m             \u001b]8;id=63781;file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=745712;file:///opt/homebrew/Caskroom/miniforge/base/envs/f1-pitstop-advisor/lib/python3.11/site-packages/kedro/io/data_catalog.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Załadowano dane dla 22 torów:\n",
      "  Catalunya: 5034 okrążeń, 14 cech\n",
      "  Spa-Francorchamps: 1592 okrążeń, 14 cech\n",
      "  Silverstone: 2495 okrążeń, 14 cech\n",
      "  Singapore: 3778 okrążeń, 14 cech\n",
      "  Hungaroring: 4951 okrążeń, 14 cech\n",
      "  Suzuka: 2754 okrążeń, 14 cech\n",
      "  Paul Ricard: 945 okrążeń, 14 cech\n",
      "  Austin: 918 okrążeń, 14 cech\n",
      "  Miami: 2160 okrążeń, 14 cech\n",
      "  Zandvoort: 5035 okrążeń, 14 cech\n",
      "  Monte Carlo: 4244 okrążeń, 14 cech\n",
      "  Montreal: 4307 okrążeń, 14 cech\n",
      "  Monza: 3898 okrążeń, 14 cech\n",
      "  Melbourne: 3071 okrążeń, 14 cech\n",
      "  Spielberg: 1124 okrążeń, 14 cech\n",
      "  Sakhir: 4415 okrążeń, 14 cech\n",
      "  Imola: 2442 okrążeń, 14 cech\n",
      "  Baku: 2734 okrążeń, 14 cech\n",
      "  Mexico City: 3843 okrążeń, 14 cech\n",
      "  Jeddah: 3430 okrążeń, 14 cech\n",
      "  Yas Marina Circuit: 3307 okrążeń, 14 cech\n",
      "  Las Vegas: 1799 okrążeń, 14 cech\n"
     ]
    }
   ],
   "source": [
    "with KedroSession.create(project_path=project_path) as session:\n",
    "    context = session.load_context()\n",
    "    dfs = context.catalog.load(\"circuit_lap_data\")\n",
    "\n",
    "print(f\"Załadowano dane dla {len(dfs)} torów:\")\n",
    "for circuit, df in dfs.items():\n",
    "    print(f\"  {circuit}: {df.shape[0]} okrążeń, {df.shape[1]} cech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a8f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare regressor configurations for testing\n",
    "\n",
    "# We test many algorithms with parameter tuning using GridSearchCV.\n",
    "# The GridSearchCVs here will be used as templates. For each circuit,\n",
    "# every of the GridSearchCVs below will be cloned and fitted to their data.\n",
    "\n",
    "# GridSearchCV configurations\n",
    "model_searches = {\n",
    "    # Linear regression\n",
    "    \"LinearRegression\": GridSearchCV(\n",
    "        make_pipeline(StandardScaler(), PCA(), LinearRegression()),\n",
    "        {\"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"RidgeCV\": GridSearchCV(\n",
    "        make_pipeline(StandardScaler(), PCA(), RidgeCV(alphas=(0.1, 1.0, 10.0))),\n",
    "        {\"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"LassoCV\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(),\n",
    "            LassoCV(max_iter=100_000, alphas=[0.001, 0.01, 0.1, 1.0]),\n",
    "        ),\n",
    "        {\"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"ElasticNetCV\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(),\n",
    "            ElasticNetCV(max_iter=100_000, l1_ratio=[0.2, 0.5, 0.8]),\n",
    "        ),\n",
    "        {\"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    # Polynomial regression\n",
    "    \"PolynomialLinearRegression\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(), PCA(), PolynomialFeatures(), LinearRegression()\n",
    "        ),\n",
    "        {\"polynomialfeatures__degree\": [2, 3], \"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"PolynomialRidgeCV\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(),\n",
    "            PolynomialFeatures(),\n",
    "            RidgeCV(alphas=(0.1, 1.0, 10.0)),\n",
    "        ),\n",
    "        {\"polynomialfeatures__degree\": [2, 3], \"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"PolynomialLassoCV\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(),\n",
    "            PolynomialFeatures(),\n",
    "            LassoCV(max_iter=100_000, alphas=[0.001, 0.01, 0.1]),\n",
    "        ),\n",
    "        {\"polynomialfeatures__degree\": [2, 3], \"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"PolynomialElasticNetCV\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(),\n",
    "            PolynomialFeatures(),\n",
    "            ElasticNetCV(max_iter=100_000, l1_ratio=[0.2, 0.5, 0.8]),\n",
    "        ),\n",
    "        {\"polynomialfeatures__degree\": [2, 3], \"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    # Bagging models\n",
    "    \"RandomForestRegressor\": GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200, 400],\n",
    "            \"max_depth\": [5, 10, 20, None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "        },\n",
    "    ),\n",
    "    \"ExtraTreesRegressor\": GridSearchCV(\n",
    "        ExtraTreesRegressor(random_state=42, n_jobs=-1),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200, 400],\n",
    "            \"max_depth\": [5, 10, 20, None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "        },\n",
    "    ),\n",
    "    # Boosting models\n",
    "    \"AdaBoostRegressor\": GridSearchCV(\n",
    "        AdaBoostRegressor(random_state=42),\n",
    "        {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.5, 1.0]},\n",
    "    ),\n",
    "    \"GradientBoostingRegressor\": GridSearchCV(\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "        },\n",
    "    ),\n",
    "    \"XGBRegressor\": GridSearchCV(\n",
    "        XGBRegressor(\n",
    "            random_state=42, n_jobs=-1, objective=\"reg:squarederror\", verbosity=0\n",
    "        ),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200, 400],\n",
    "            \"max_depth\": [3, 6, 10],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0],\n",
    "        },\n",
    "    ),\n",
    "    # Support vector models\n",
    "    \"SVR_linear\": GridSearchCV(\n",
    "        make_pipeline(StandardScaler(), PCA(), SVR(kernel=\"linear\")),\n",
    "        {\"svr__C\": [0.1, 1, 10, 100], \"pca__n_components\": [0.98, 0.95, 0.9]},\n",
    "    ),\n",
    "    \"SVR_rbf\": GridSearchCV(\n",
    "        make_pipeline(StandardScaler(), PCA(), SVR(kernel=\"rbf\")),\n",
    "        {\n",
    "            \"svr__C\": [0.1, 1, 10],\n",
    "            \"svr__gamma\": [\"scale\", 0.01, 0.1, 1.0],\n",
    "            \"pca__n_components\": [0.98, 0.95, 0.9],\n",
    "        },\n",
    "    ),\n",
    "    # MLP\n",
    "    \"MLPRegressor\": GridSearchCV(\n",
    "        make_pipeline(\n",
    "            StandardScaler(), PCA(), MLPRegressor(max_iter=100_000, random_state=42)\n",
    "        ),\n",
    "        {\n",
    "            \"mlpregressor__hidden_layer_sizes\": [\n",
    "                (16,),\n",
    "                (24,),\n",
    "                (24, 12),\n",
    "                (16, 16),\n",
    "                (16, 8),\n",
    "            ],\n",
    "            \"mlpregressor__activation\": [\"relu\", \"tanh\"],\n",
    "            \"mlpregressor__alpha\": [0.0001, 0.001, 0.01],\n",
    "            \"mlpregressor__learning_rate_init\": [0.001, 0.01],\n",
    "            \"pca__n_components\": [0.98, 0.95, 0.9],\n",
    "        },\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models for Catalunya\n",
      "  Shape: (5034, 12), Kolumny: ['IsPitLap', 'TyreLife', 'FreshTyre', 'LapNumber', 'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed', 'CompoundNumeric']\n",
      "  Shape po imputajci/usunięciu NAN: (5034, 12), Kolumny: ['IsPitLap', 'TyreLife', 'FreshTyre', 'LapNumber', 'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed', 'CompoundNumeric']\n",
      "Fitting LinearRegression;                         took 0.04 seconds\n",
      "Fitting RidgeCV;                                  took 0.04 seconds\n",
      "Fitting LassoCV;                                  took 0.06 seconds\n",
      "Fitting ElasticNetCV;                             took 0.52 seconds\n",
      "Fitting PolynomialLinearRegression;               took 0.45 seconds\n",
      "Fitting PolynomialRidgeCV;                        took 0.88 seconds\n",
      "Fitting PolynomialLassoCV;                        took 4.19 seconds\n",
      "Fitting PolynomialElasticNetCV;                   took 19.05 seconds\n",
      "Fitting RandomForestRegressor;                    "
     ]
    }
   ],
   "source": [
    "# Fit every single circuit/GridSearch configuration\n",
    "models_and_circuits = {}\n",
    "\n",
    "for name in model_searches.keys():\n",
    "    models_and_circuits[name] = {}\n",
    "\n",
    "for circuit, data in dfs.items():\n",
    "    print(f\"Fitting models for {circuit}\")\n",
    "    circuit_start = time.time()\n",
    "\n",
    "    X = data.drop([\"LapTimeZScore\", \"Compound\"], axis=1).astype(float)\n",
    "    y = data[\"LapTimeZScore\"].astype(float)\n",
    "\n",
    "    print(f\"  Shape: {X.shape}, Kolumny: {list(X.columns)}\")\n",
    "\n",
    "    # wersja minimum - z usuwnaiem danych\n",
    "    # X = X.dropna()\n",
    "    # y = y.loc[X.index]\n",
    "\n",
    "    mask = ~y.isna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
    "\n",
    "    print(f\"  Shape po imputajci/usunięciu NAN: {X.shape}, Kolumny: {list(X.columns)}\")\n",
    "\n",
    "    for name, model_search in model_searches.items():\n",
    "        print(f\"Fitting {name};\".ljust(50), end=\"\")\n",
    "        model_start = time.time()\n",
    "\n",
    "        model_search_copy = clone(model_search)\n",
    "        model_search_copy.fit(X, y)\n",
    "        models_and_circuits[name][circuit] = model_search_copy\n",
    "\n",
    "        print(f\"took {round(time.time() - model_start, 2)} seconds\")\n",
    "\n",
    "    print(\n",
    "        f'Took a total of {round(time.time() - circuit_start, 2)} seconds to fit all models for circuit \"{circuit}\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098da9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models for later use\n",
    "context.catalog.save(\"initial_models\", models_and_circuits)\n",
    "print(\"Zapisano modele\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scores for each GridSearch and circuit\n",
    "all_scores = {}\n",
    "for key in models_and_circuits.keys():\n",
    "    scores = {}\n",
    "    for circuit, model in models_and_circuits[key].items():\n",
    "        scores[circuit] = model.best_score_\n",
    "    all_scores[key] = scores\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores)\n",
    "\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa140e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show score statistics for each model\n",
    "# MinScore is very important. A good model should perform reasonably well for all tracks.\n",
    "model_scores_df = pd.DataFrame(\n",
    "    {\n",
    "        \"MeanScore\": all_scores.mean(axis=\"index\"),\n",
    "        \"MedianScore\": all_scores.median(axis=\"index\"),\n",
    "        \"ScoreVariance\": all_scores.var(axis=\"index\"),\n",
    "        \"MinScore\": all_scores.min(axis=\"index\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "model_scores_df.sort_values(by=[\"MeanScore\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302a1ed",
   "metadata": {},
   "source": [
    "## Result interpretation\n",
    "### The top-2\n",
    "**XGBRegressor is a clear winner**. The lowest score it got is over 0.64, mean and median scores are highest of all models, while score variance is low. It is clear that this algorithm reliably provides good results.\n",
    "\n",
    "**GradientBoostingRegressor** is a close runner up, with similar characteristics, albeit somewhat less accurate and less consistent. This does not come as a surprise, since it uses a similar but less advanced algorithm to XGBoost. \n",
    "\n",
    "### Remaining results\n",
    "The rest of the models have serious flaws. For example, **RandomForestRegressor**, despite having decent overall scores, has a higher score variance and got a score below 0.2 for one of the tracks. **ExtraTreesRegressor** is better in that regard, but still inferior to out top-2 models. \n",
    "\n",
    "The rest of the regressors perform significantly worse than the others, with versions of polynomial and linear regression having particularly low performance. There are some outlying values, even negative ones, in these models. Considering that XGBoost is a clear winner, I do not deem it necessary to look into this further at this point.\n",
    "\n",
    "### To sum up\n",
    "It appears that *boosting models*, particularly XGBRegressor and GradientBoostingRegressor, are the best. These are the models that will be optimized and tested further.\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how the best models perform on every circuit\n",
    "relevant_scores = all_scores.loc[:, [\"XGBRegressor\", \"GradientBoostingRegressor\"]]\n",
    "track_scores_df = pd.DataFrame(\n",
    "    {\n",
    "        \"MeanScore\": relevant_scores.mean(axis=\"columns\"),\n",
    "        \"XGBRegressorScore\": relevant_scores[\"XGBRegressor\"],\n",
    "        \"GradientBoostingRegressorScore\": relevant_scores[\"GradientBoostingRegressor\"],\n",
    "        \"DataPointCount\": [df.shape[0] for df in dfs.values()],\n",
    "    }\n",
    ")\n",
    "track_scores_df.sort_values(by=[\"MeanScore\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61fa454",
   "metadata": {},
   "source": [
    "## About scores by circuit\n",
    "Scores clearly vary a lot depending on the circuit. It is important to note that both the characteristics of the circuit itself, as well as how much data we have on each circuit has a big effect. For some circuits we only have data from one session, which is an obvious limitation and could affect score in different ways. The score tends to be higher for circuits with less than 2000 data points, possibly because the data points only come from one or two sessions in those cases. This makes it very likely for weather to be roughly constant throughout the data relevant to them, skewing CV results in favour of the model.\n",
    "\n",
    "### Point in favour of the results\n",
    "Even in the worst case, XGBoost had a mean score of over 0.64, which means it accounted for 64% of target attribute variance. <br> \n",
    "The target attribute in this case the driver's lap time z-score within each session. Z-score in this case basically denotes how good the lap was compared to the other laps the same driver completed in the same session. This means that for the most unpredictable circuit, our model accounted for 64% of how pit stops and weather affect driver performance. For over 70% of the circuits, the model accounted for over 80% of those differences.\n",
    "\n",
    "Therefore, it is clear to me that boosting models can produce decent-to-excellent results in general, even if some scores are exaggerated due to insufficient data size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
